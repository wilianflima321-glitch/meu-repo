# 23_CRITICAL_LIMITATIONS_AND_MARKET_SUPERIORITY_PLAN_2026-02-28
Status: EXECUTION CRITIQUE
Date: 2026-02-28
Owner: Chief Architecture + Critical Agent

## 1) Purpose
Consolidate the real critical limitations for games/films/apps and define what must be built to achieve market-leading quality without scope drift.

Scope lock:
1. single platform shell model (`/dashboard` entry, `/ide` advanced mode)
2. explicit capability/error/deprecation contracts
3. no fake-success
4. no desktop parity claim without operational evidence

## 2) Factual baseline (repo evidence)
1. Structural connectivity gate: `npm run qa:repo-connectivity` -> PASS.
2. Interface critical sweep (`cloud-web-app/web/docs/INTERFACE_CRITICAL_SWEEP.md`):
- `legacy-accent-tokens=0`
- `admin-light-theme-tokens=0`
- `admin-status-light-tokens=0`
- `blocking-browser-dialogs=0`
- `not-implemented-ui=6`
3. Deprecation contracts active with explicit `410` metadata:
- `/api/workspace/tree`
- `/api/workspace/files`
- `/api/auth/sessions`
- `/api/auth/sessions/[id]`
4. Remaining architecture pressure:
- large files (`>=1200`) are still numerous in `cloud-web-app/web`;
- dashboard shell monolith remains a primary hotspot.
5. Canonical documentation drift risk remains:
- high markdown volume outside `docs/master`;
- legacy path references still present in historical docs.

## 3) Critical limitations that block "best-in-market"
## 3.1 AI reliability limitations
1. Long-horizon consistency is still the hardest problem (character, scene, system behavior over many iterations).
2. Stochastic generation requires deterministic verification before apply.
3. Cost and latency increase quickly with larger context and parallel agents.
4. Provider dependency remains a business risk (quota/outage/pricing).

## 3.2 Games limitations
1. Content generation does not guarantee gameplay quality (pacing, difficulty, progression loops).
2. Logic generated by LLM can compile and still fail runtime/balance goals.
3. 3D assets require validation chain (topology/rig/material/perf), not prompt-only generation.

## 3.3 Films/media limitations
1. Temporal continuity is not guaranteed by base text/video generation alone.
2. Shot-level control and identity consistency need dedicated control pipelines.
3. Final quality depends on post-processing/runtime stages beyond LLM text output.

## 3.4 Apps/software limitations
1. Multi-file change impact is still a frequent source of silent regression.
2. Agent edits require deterministic guardrails (`plan -> patch -> validate -> apply -> rollback`).
3. Enterprise-readiness depends on observability and repeatable release gates, not one-off demos.

## 4) Shared subsystem strategy (one core for games/films/apps)
All three verticals should reuse the same core stack:
1. orchestration core: Planner/Coder/Reviewer/Verifier with serial apply
2. project memory core: approved artifacts + dependency graph + decision history
3. validation core: lint/type/build/smoke/eval by domain
4. runtime core: preview/execute with explicit unsupported gates
5. economics core: budget caps, quota policy, per-session/per-agent cost telemetry

Domain-specific layers stay thin:
1. games-specific validators and gameplay QA loops
2. films-specific continuity and shot controls
3. apps-specific dependency/impact analysis and integration checks

## 5) What "surpass market" actually means here
No inflated claim. Superiority must be operational:
1. higher success rate of accepted changes after automated validation
2. lower regression rate in critical journeys
3. predictable cost-to-result per completed task
4. faster first useful outcome with explicit constraints and truthful gates

This is a workflow/reliability competition, not a raw-model-marketing competition.

## 6) Execution priorities (blocking order)
### P0-A Governance and truth consistency
1. keep `docs/master` as only execution source
2. eliminate stale canonical references to legacy paths
3. keep structural gate mandatory in all pipelines

### P0-B Monolith risk reduction
1. continue splitting `AethelDashboard` into domain blocks
2. enforce ownership boundaries by module
3. avoid new UI feature expansion before split reaches stable boundaries

### P0-C Capability truth hardening
1. keep `NOT_IMPLEMENTED` explicit where capability is not operational
2. keep deprecation metadata complete until telemetry cutoff criteria is met
3. preserve no-CTA policy for gated critical-path capabilities

### P1-A Domain quality engines
1. gameplay quality validator loop (games)
2. continuity/identity validator loop (films)
3. dependency-impact validator loop (apps)

### P1-B Cost and plan precision
1. dual entitlement enforcement (time vs usage)
2. hard-stop on variable-cost features when credits reach zero
3. premium feature access retained until cycle end for paid plans

## 7) Claims prohibited until evidence exists
1. full Unreal/Premiere parity in browser
2. L4/L5 production readiness without reproducible ops evidence
3. advanced real-time collaboration readiness without SLO + stress validation

## 8) Immediate backlog additions
1. Add canonical drift check for stale legacy path references in `docs/master`.
2. Continue decomposition of `cloud-web-app/web/components/AethelDashboard.tsx`.
3. Run full freeze gate suite and publish evidence package in canonical docs.
4. Execute cross-domain gap matrix in `docs/master/24_GAMES_FILMS_APPS_GAP_ALIGNMENT_MATRIX_2026-02-28.md`.
5. Use `docs/master/25_MARKET_LIMITATIONS_PARITY_PLAYBOOK_2026-02-28.md` as comparator guardrail before any "equal/superior" claim.
6. Use `docs/master/26_CANONICAL_ALIGNMENT_BASELINE_2026-02-28.md` as the active numeric/status anchor.
7. Keep canonical coherence gate green:
- `npm run qa:canonical-doc-alignment`.
